{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if \"__project_dir__\" not in globals():\n",
    "    __project_dir__ = Path.cwd().parents[1].resolve()\n",
    "\n",
    "sys.path.append(__project_dir__)\n",
    "os.chdir(__project_dir__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tidytcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\n",
    "    \"tcr_data/raw/tanno\"\n",
    ")\n",
    "preprocessed_dir = Path(\n",
    "    \"tcr_data/preprocessed/tanno\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv(raw_dir / \"data\" / \"A1 memory.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.sort_values(by=\"Clustered\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for f in (raw_dir / \"data\").iterdir():\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "\n",
    "    # Filter for potential mispairings\n",
    "    df = df.sort_values(by=\"Clustered\", ascending=False)\n",
    "    df = df.drop_duplicates(\"CDRH3_NT\", keep=\"first\")\n",
    "    df = df.drop_duplicates(\"CDRL3_NT\", keep=\"first\")\n",
    "\n",
    "    df = df[[\"VL\", \"CDRL3_AA\", \"JL\", \"VH\", \"CDRH3_AA\", \"JH\"]]\n",
    "    df.columns = [\"TRAV\", \"CDR3A\", \"TRAJ\", \"TRBV\", \"CDR3B\", \"TRBJ\"]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "combined = pd.concat(dfs, axis=\"index\")\n",
    "\n",
    "combined[\"TRAV\"] = combined[\"TRAV\"].map(\n",
    "    lambda x: tidytcells.tr.standardise(x, enforce_functional=True)\n",
    ")\n",
    "combined[\"TRAJ\"] = combined[\"TRAJ\"].map(\n",
    "    lambda x: tidytcells.tr.standardise(x, enforce_functional=True)\n",
    ")\n",
    "combined[\"TRBV\"] = combined[\"TRBV\"].map(\n",
    "    lambda x: tidytcells.tr.standardise(x, enforce_functional=True)\n",
    ")\n",
    "combined[\"TRBJ\"] = combined[\"TRBJ\"].map(\n",
    "    lambda x: tidytcells.tr.standardise(x, enforce_functional=True)\n",
    ")\n",
    "\n",
    "combined = combined.dropna(subset=[\"TRAV\", \"CDR3A\", \"TRBV\", \"CDR3B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.1\n",
    "test_rows = int(test_frac * len(combined))\n",
    "\n",
    "shuffled = combined.sample(frac=1, random_state=12345)\n",
    "\n",
    "test = shuffled.iloc[:test_rows]\n",
    "train = shuffled.iloc[test_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_similar_clones(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    if not \"clone_count\" in df:\n",
    "        df[\"clone_count\"] = 1\n",
    "\n",
    "    df = df.groupby(\n",
    "        [\"TRAV\", \"CDR3A\", \"TRAJ\", \"TRBV\", \"CDR3B\", \"TRBJ\"],\n",
    "        as_index=False,\n",
    "        dropna=False\n",
    "    ).aggregate({\"clone_count\": \"sum\"})\n",
    "\n",
    "    df[[\"Epitope\", \"MHCA\", \"MHCB\"]] = pd.NA \n",
    "\n",
    "    df = df[[\"TRAV\", \"CDR3A\", \"TRAJ\", \"TRBV\", \"CDR3B\", \"TRBJ\", \"Epitope\", \"MHCA\", \"MHCB\", \"clone_count\"]]\n",
    "    \n",
    "    return df.sample(frac=1, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combine_similar_clones(combined)\n",
    "test = combine_similar_clones(test)\n",
    "train = combine_similar_clones(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tcr_string(tcr_row):\n",
    "    return \"{}{}{}{}{}{}\".format(\n",
    "        tcr_row[\"TRAV\"],\n",
    "        tcr_row[\"CDR3A\"],\n",
    "        tcr_row[\"TRAJ\"],\n",
    "        tcr_row[\"TRBV\"],\n",
    "        tcr_row[\"CDR3B\"],\n",
    "        tcr_row[\"TRBJ\"]\n",
    "    )\n",
    "\n",
    "def remove_tcrs_in_b_from_a(df_a, df_b):\n",
    "    tcrs_in_b = set(df_b.apply(generate_tcr_string, axis=1).unique())\n",
    "\n",
    "    tcrs_to_remove_from_a = df_a.apply(generate_tcr_string, axis=1).map(lambda tcr: tcr in tcrs_in_b)\n",
    "\n",
    "    return df_a.copy()[~tcrs_to_remove_from_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_tcrs_in_b_from_a(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travs = tidytcells.tr.query(precision=\"gene\", functionality=\"F\", contains_pattern=\"TRAV\")\n",
    "trajs = tidytcells.tr.query(precision=\"gene\", functionality=\"F\", contains_pattern=\"TRAJ\")\n",
    "trbvs = tidytcells.tr.query(precision=\"gene\", functionality=\"F\", contains_pattern=\"TRBV\")\n",
    "trbjs = tidytcells.tr.query(precision=\"gene\", functionality=\"F\", contains_pattern=\"TRBJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train, test):\n",
    "    assert travs == set(dataset[\"TRAV\"].dropna())\n",
    "    assert trajs == set(dataset[\"TRAJ\"].dropna())\n",
    "    assert trbvs == set(dataset[\"TRBV\"].dropna())\n",
    "    assert trbjs == set(dataset[\"TRBJ\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_counts = dict()\n",
    "\n",
    "for bv in combined[\"TRBV\"].dropna().unique():\n",
    "    bv_count = combined[\"clone_count\"][combined[\"TRBV\"] == bv].sum()\n",
    "    bv_counts[bv] = int(bv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trbv_frequencies.json\", \"w\") as f:\n",
    "    json.dump(bv_counts, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pGen of TCRs in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLGA setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olga import load_model\n",
    "import olga.generation_probability as pgen\n",
    "\n",
    "OLGA_PATH = Path(\".venv\") / \"lib64\" / \"python3.11\" / \"site-packages\" / \"olga\"\n",
    "DEFAULT_HUMAN_T_BETA_PATH = OLGA_PATH / \"default_models\" / \"human_T_beta\"\n",
    "DEFAULT_HUMAN_T_ALPHA_PATH = OLGA_PATH / \"default_models\" / \"human_T_alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_pgen_model():\n",
    "    params_file_name = DEFAULT_HUMAN_T_ALPHA_PATH / \"model_params.txt\"\n",
    "    marginals_file_name = DEFAULT_HUMAN_T_ALPHA_PATH / \"model_marginals.txt\"\n",
    "    v_anchor_pos_file = DEFAULT_HUMAN_T_ALPHA_PATH / \"V_gene_CDR3_anchors.csv\"\n",
    "    j_anchor_pos_file = DEFAULT_HUMAN_T_ALPHA_PATH / \"J_gene_CDR3_anchors.csv\"\n",
    "\n",
    "    genomic_data = load_model.GenomicDataVJ()\n",
    "    genomic_data.load_igor_genomic_data(params_file_name, v_anchor_pos_file, j_anchor_pos_file)\n",
    "\n",
    "    generative_model = load_model.GenerativeModelVJ()\n",
    "    generative_model.load_and_process_igor_model(marginals_file_name)\n",
    "\n",
    "    pgen_model = pgen.GenerationProbabilityVJ(generative_model, genomic_data)\n",
    "\n",
    "    return pgen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_pgen_model():\n",
    "    params_file_name = DEFAULT_HUMAN_T_BETA_PATH / \"model_params.txt\"\n",
    "    marginals_file_name = DEFAULT_HUMAN_T_BETA_PATH / \"model_marginals.txt\"\n",
    "    v_anchor_pos_file = DEFAULT_HUMAN_T_BETA_PATH / \"V_gene_CDR3_anchors.csv\"\n",
    "    j_anchor_pos_file = DEFAULT_HUMAN_T_BETA_PATH / \"J_gene_CDR3_anchors.csv\"\n",
    "\n",
    "    genomic_data = load_model.GenomicDataVDJ()\n",
    "    genomic_data.load_igor_genomic_data(params_file_name, v_anchor_pos_file, j_anchor_pos_file)\n",
    "\n",
    "    generative_model = load_model.GenerativeModelVDJ()\n",
    "    generative_model.load_and_process_igor_model(marginals_file_name)\n",
    "\n",
    "    pgen_model = pgen.GenerationProbabilityVDJ(generative_model, genomic_data)\n",
    "\n",
    "    return pgen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pgen(model, cdr3, v, j) -> float:\n",
    "    if pd.isna(cdr3):\n",
    "        return None\n",
    "    \n",
    "    if pd.isna(v):\n",
    "        v = None\n",
    "    if pd.isna(j):\n",
    "        j = None\n",
    "\n",
    "    return model.compute_aa_CDR3_pgen(cdr3, v, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute pGens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_model = get_alpha_pgen_model()\n",
    "\n",
    "test[\"alpha_pgen\"] = test.apply(\n",
    "    lambda row: compute_pgen(alpha_model, row[\"CDR3A\"], row[\"TRAV\"], row[\"TRAJ\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_model = get_beta_pgen_model()\n",
    "\n",
    "test[\"beta_pgen\"] = test.apply(\n",
    "    lambda row: compute_pgen(beta_model, row[\"CDR3B\"], row[\"TRBV\"], row[\"TRBJ\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(preprocessed_dir / \"combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(preprocessed_dir / \"train.csv\", index=False)\n",
    "test.to_csv(preprocessed_dir / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sample(n=5, random_state=420).to_csv(\n",
    "    preprocessed_dir / \"exemplars.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bab11497baf8882c4e95e2d544b4f7a8d499018a7e93af1d4b5fac976897075f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
